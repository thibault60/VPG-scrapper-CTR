import streamlit as st
import pandas as pd
from serpapi import GoogleSearch
from concurrent.futures import ThreadPoolExecutor, as_completed
from io import BytesIO

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="VisibilitÃ© Voyage PrivÃ© â€“ SERP", layout="wide")

try:
    SERPAPI_KEY = st.secrets["serpapi_key"]
except Exception:
    st.error("âŒ ClÃ© SerpApi manquante dans `.streamlit/secrets.toml`.")
    st.stop()

VP_DOMAIN = "voyageprive.com"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. RequÃªtes prÃ©dÃ©finies (modifiables via l'UI)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_QUERIES = """voyage tout compris pas cher
sÃ©jour derniÃ¨re minute
hÃ´tel tout inclus bord de mer"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Sidebar
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ ParamÃ¨tres")
    hl = st.selectbox("Langue (hl)", ["fr", "en", "es", "de", "it"], index=0)
    gl = st.selectbox("Pays (gl)", ["fr", "us", "es", "de", "it"], index=0)
    max_workers = st.slider("Threads simultanÃ©s", 1, 8, 4)
    num_results = st.slider("RÃ©sultats organiques analysÃ©s", 10, 30, 10, step=10)

    st.markdown("---")
    st.markdown(
        "**Domaine cible**  \n`voyageprive.com`  \n\nL'app extrait uniquement les URLs VP dans :"
        "\n- ğŸ”µ RÃ©sultats organiques\n- ğŸ›ï¸ Carrousel offres"
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Zone de saisie des requÃªtes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ” VisibilitÃ© Voyage PrivÃ© sur Google")
st.markdown(
    "Entrez vos requÃªtes (une par ligne). L'app rÃ©cupÃ¨re **toutes les URLs voyageprive.com** "
    "prÃ©sentes dans les rÃ©sultats organiques et les carrousels d'offres."
)

queries_raw = st.text_area(
    "ğŸ“‹ Liste de requÃªtes",
    value=DEFAULT_QUERIES,
    height=180,
    help="Une requÃªte par ligne.",
)
queries = [q.strip() for q in queries_raw.splitlines() if q.strip()]
st.caption(f"**{len(queries)} requÃªte(s)** chargÃ©e(s)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Extraction SerpApi
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_vp_results(query: str, hl: str, gl: str, num: int) -> list[dict]:
    """Retourne toutes les URLs VP trouvÃ©es pour une requÃªte donnÃ©e."""
    params = {
        "q": query,
        "api_key": SERPAPI_KEY,
        "hl": hl,
        "gl": gl,
        "num": num,
        "engine": "google",
    }
    try:
        search = GoogleSearch(params)
        data = search.get_dict()
    except Exception as exc:
        return [_error_row(query, str(exc))]

    rows = []

    # â”€â”€ RÃ©sultats organiques â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for pos, r in enumerate(data.get("organic_results", []), start=1):
        link = r.get("link", "")
        if VP_DOMAIN in link:
            rows.append({
                "RequÃªte": query,
                "Type": "ğŸ”µ Organique",
                "Position": pos,
                "Titre": r.get("title", "â€”"),
                "URL": link,
                "Snippet": r.get("snippet", "â€”"),
                "Date snippet": r.get("date", ""),
            })

    # â”€â”€ Carrousels d'offres / shopping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    carousel_sources = [
        ("shopping_results",    "ğŸ›ï¸ Shopping"),
        ("inline_shopping_results", "ğŸ›ï¸ Inline Shopping"),
        ("ads",                 "ğŸ“¢ Annonce"),
        ("top_stories",         "ğŸ“° Top Stories"),
        ("knowledge_graph",     "ğŸ“– Knowledge Graph"),
    ]

    for key, label in carousel_sources:
        items = data.get(key, [])
        if isinstance(items, dict):
            items = [items]
        for item in items:
            link = item.get("link", "") or item.get("url", "")
            if VP_DOMAIN in link:
                rows.append({
                    "RequÃªte": query,
                    "Type": label,
                    "Position": item.get("position", "â€”"),
                    "Titre": item.get("title", "â€”"),
                    "URL": link,
                    "Snippet": item.get("snippet", item.get("price", "â€”")),
                    "Date snippet": "",
                })

    # â”€â”€ Deals / offres carrousel (structure spÃ©cifique) â”€â”€
    immersive = data.get("immersive_products", []) or data.get("inline_products", [])
    for item in immersive:
        link = item.get("link", "")
        if VP_DOMAIN in link:
            rows.append({
                "RequÃªte": query,
                "Type": "ğŸ  Carrousel produits",
                "Position": item.get("position", "â€”"),
                "Titre": item.get("title", "â€”"),
                "URL": link,
                "Snippet": item.get("price", "â€”"),
                "Date snippet": "",
            })

    if not rows:
        rows.append({
            "RequÃªte": query,
            "Type": "âŒ Absent",
            "Position": "â€”",
            "Titre": "Voyage PrivÃ© non trouvÃ© dans les rÃ©sultats",
            "URL": "",
            "Snippet": "",
            "Date snippet": "",
        })

    return rows


def _error_row(query: str, msg: str) -> dict:
    return {
        "RequÃªte": query,
        "Type": "âš ï¸ Erreur",
        "Position": "â€”",
        "Titre": msg,
        "URL": "",
        "Snippet": "",
        "Date snippet": "",
    }


@st.cache_data(ttl=3_600, show_spinner=False)
def run_all(queries_tuple: tuple, hl: str, gl: str, num: int, workers: int) -> pd.DataFrame:
    rows = []
    progress = st.progress(0.0, text="ğŸ”„ Analyse des SERP en coursâ€¦")
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {
            executor.submit(extract_vp_results, q, hl, gl, num): q
            for q in queries_tuple
        }
        total = len(futures)
        for i, future in enumerate(as_completed(futures), 1):
            rows.extend(future.result())
            progress.progress(i / total, text=f"ğŸ”„ {i}/{total} requÃªtes analysÃ©esâ€¦")
    progress.empty()
    return pd.DataFrame(rows)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Lancement + Affichage
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if st.button("ğŸš€ Lancer l'extraction", type="primary", disabled=len(queries) == 0):
    if not queries:
        st.warning("Ajoutez au moins une requÃªte.")
        st.stop()

    df = run_all(tuple(queries), hl, gl, num_results, max_workers)

    # â”€â”€ KPIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total = len(df)
    present = df[df["Type"] != "âŒ Absent"]
    absent = df[df["Type"] == "âŒ Absent"]

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("RequÃªtes analysÃ©es", len(queries))
    col2.metric("RequÃªtes avec VP prÃ©sent", len(present["RequÃªte"].unique()) if not present.empty else 0)
    col3.metric("RÃ©sultats VP trouvÃ©s", len(present))
    col4.metric("RequÃªtes sans VP", len(absent))

    st.markdown("---")

    # â”€â”€ Tableau principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“Š RÃ©sultats dÃ©taillÃ©s")

    # Filtres
    col_f1, col_f2 = st.columns(2)
    type_filter = col_f1.multiselect(
        "Filtrer par type",
        options=df["Type"].unique().tolist(),
        default=df["Type"].unique().tolist(),
    )
    query_filter = col_f2.multiselect(
        "Filtrer par requÃªte",
        options=df["RequÃªte"].unique().tolist(),
        default=df["RequÃªte"].unique().tolist(),
    )

    df_filtered = df[df["Type"].isin(type_filter) & df["RequÃªte"].isin(query_filter)]

    st.dataframe(
        df_filtered,
        use_container_width=True,
        height=500,
        column_config={
            "URL": st.column_config.LinkColumn("URL", display_text="ğŸ”— Voir"),
        },
        column_order=["RequÃªte", "Type", "Position", "Titre", "URL", "Snippet"],
    )

    # â”€â”€ Vue groupÃ©e par requÃªte â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    st.subheader("ğŸ” DÃ©tail par requÃªte")
    for query in df["RequÃªte"].unique():
        subset = df[df["RequÃªte"] == query]
        has_vp = subset[subset["Type"] != "âŒ Absent"]
        label = f"{'âœ…' if not has_vp.empty else 'âŒ'} {query} â€” {len(has_vp)} rÃ©sultat(s) VP"
        with st.expander(label):
            for _, row in subset.iterrows():
                if row["Type"] == "âŒ Absent":
                    st.info("Voyage PrivÃ© n'apparaÃ®t pas dans les rÃ©sultats analysÃ©s.")
                else:
                    st.markdown(f"**{row['Type']}** â€” Position `{row['Position']}`")
                    st.markdown(f"**{row['Titre']}**")
                    if row["URL"]:
                        st.markdown(f"[{row['URL']}]({row['URL']})")
                    if row["Snippet"] and row["Snippet"] not in ("â€”", ""):
                        st.caption(row["Snippet"])
                    st.markdown("---")

    # â”€â”€ Exports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    col_dl1, col_dl2 = st.columns(2)

    csv = df.to_csv(index=False).encode("utf-8")
    col_dl1.download_button(
        "ğŸ’¾ TÃ©lÃ©charger CSV",
        data=csv,
        file_name="vp_serp_visibility.csv",
        mime="text/csv",
    )

    xlsx_buffer = BytesIO()
    with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="VP_SERP")
        # Onglet rÃ©sumÃ©
        summary = (
            df[df["Type"] != "âŒ Absent"]
            .groupby(["RequÃªte", "Type"])
            .size()
            .reset_index(name="Nombre d'URLs VP")
        )
        summary.to_excel(writer, index=False, sheet_name="RÃ©sumÃ©")
    xlsx_buffer.seek(0)
    col_dl2.download_button(
        "ğŸ“Š TÃ©lÃ©charger XLSX",
        data=xlsx_buffer,
        file_name="vp_serp_visibility.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
